{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quiz: Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.truncated_normal([2, 2, 1, 3]))\n",
    "    F_b = tf.Variable(tf.zeros(3))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "#     return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "    return tf.nn.bias_add(tf.nn.conv2d(input, F_W, strides, padding), F_b)\n",
    "\n",
    "out = conv2d(X)\n",
    "\n",
    "b_tmp = tf.constant([1.0, 2.0, 3.0])\n",
    "\n",
    "# Lecture Note: The tf.nn.bias_add() function adds a 1-d bias to the last dimension in a matrix. (Note: using tf.add() doesn't work when the tensors aren't the same shape.)\n",
    "# Rui test: all three works here\n",
    "# out_tmp = out + b_tmp\n",
    "# out_tmp = tf.add(out, b_tmp)\n",
    "out_tmp = tf.nn.bias_add(out, b_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 3)\n",
      "[[[[ -3.61456823  -5.82835484  -0.91199523]\n",
      "   [  6.4423337   14.23735046   4.33617592]]\n",
      "\n",
      "  [[  1.00528979 -19.34800911 -17.04005432]\n",
      "   [ -1.41689062  -4.32622719  -4.27193022]]]]\n",
      "[[-3.61456823  6.4423337 ]\n",
      " [ 1.00528979 -1.41689062]]\n",
      "[[ -5.82835484  14.23735046]\n",
      " [-19.34800911  -4.32622719]]\n",
      "[[ -0.91199523   4.33617592]\n",
      " [-17.04005432  -4.27193022]]\n",
      "b_tmp_val\n",
      " [ 1.  2.  3.]\n",
      "out_tmp_val\n",
      " [[[[ -2.61456823  -3.82835484   2.08800483]\n",
      "   [  7.4423337   16.23735046   7.33617592]]\n",
      "\n",
      "  [[  2.00528979 -17.34800911 -14.04005432]\n",
      "   [ -0.41689062  -2.32622719  -1.27193022]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out_val, b_tmp_val, out_tmp_val = sess.run([out, b_tmp, out_tmp])\n",
    "    print(out_val.shape)\n",
    "    print(out_val)\n",
    "    for i in range(3):\n",
    "        print(out_val[0, :, :, i]) \n",
    "        \n",
    "    print('b_tmp_val\\n', b_tmp_val)\n",
    "    print('out_tmp_val\\n', out_tmp_val)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.truncated_normal([3, 3, 1, 3]))\n",
    "    F_b = tf.Variable(tf.zeros(3))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 1, 1, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 3)\n",
      "[[[[ -8.94327641   9.03826332  -9.48495197]\n",
      "   [-15.12922287   1.65697861  -6.69941425]]\n",
      "\n",
      "  [[-13.37130928  29.46146202 -25.25383949]\n",
      "   [ -8.12068176   6.2870245   -1.013906  ]]]]\n",
      "[[ -8.94327641 -15.12922287]\n",
      " [-13.37130928  -8.12068176]]\n",
      "[[  9.03826332   1.65697861]\n",
      " [ 29.46146202   6.2870245 ]]\n",
      "[[ -9.48495197  -6.69941425]\n",
      " [-25.25383949  -1.013906  ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out_val = sess.run(out)\n",
    "    print(out_val.shape)\n",
    "    print(out_val)\n",
    "    for i in range(3):\n",
    "        print(out_val[0, :, :, i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Quiz: Max Pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the values to `strides` and `ksize` such that\n",
    "the output shape after pooling is (1, 2, 2, 1).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "    \n",
    "out = maxpool(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out_val= sess.run(out)\n",
    "    print(out_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. CNNs in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# number of samples to calculate validation and accuracy\n",
    "# decrease this if you're running out of memory\n",
    "test_valid_size = 256\n",
    "\n",
    "# network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # dropout (probability to keep units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store weights & biases\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 56891.6328 Validation Accuracy: 0.070312\n",
      "Epoch  1, Batch   2 -Loss: 46594.3984 Validation Accuracy: 0.078125\n",
      "Epoch  1, Batch   3 -Loss: 37274.9844 Validation Accuracy: 0.089844\n",
      "Epoch  1, Batch   4 -Loss: 34622.7891 Validation Accuracy: 0.089844\n",
      "Epoch  1, Batch   5 -Loss: 30409.2266 Validation Accuracy: 0.089844\n",
      "Epoch  1, Batch   6 -Loss: 27175.3965 Validation Accuracy: 0.109375\n",
      "Epoch  1, Batch   7 -Loss: 23384.9805 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch   8 -Loss: 25059.6426 Validation Accuracy: 0.128906\n",
      "Epoch  1, Batch   9 -Loss: 24200.0312 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch  10 -Loss: 20925.2480 Validation Accuracy: 0.144531\n",
      "Epoch  1, Batch  11 -Loss: 20335.0078 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  12 -Loss: 22964.1738 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch  13 -Loss: 20590.6973 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  14 -Loss: 18382.9648 Validation Accuracy: 0.175781\n",
      "Epoch  1, Batch  15 -Loss: 17838.3398 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  16 -Loss: 17171.1465 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  17 -Loss: 15341.8125 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  18 -Loss: 21184.0586 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  19 -Loss: 16282.0293 Validation Accuracy: 0.238281\n",
      "Epoch  1, Batch  20 -Loss: 15831.2119 Validation Accuracy: 0.250000\n",
      "Epoch  1, Batch  21 -Loss: 15065.6680 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  22 -Loss: 15966.9160 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  23 -Loss: 13956.1074 Validation Accuracy: 0.250000\n",
      "Epoch  1, Batch  24 -Loss: 15091.9199 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  25 -Loss: 15284.5078 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  26 -Loss: 14255.6670 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  27 -Loss: 14265.2666 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  28 -Loss: 12914.5615 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  29 -Loss: 13298.6738 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  30 -Loss: 11794.1699 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  31 -Loss: 12292.0400 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  32 -Loss: 11410.2207 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  33 -Loss: 11926.4648 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  34 -Loss: 10229.7598 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  35 -Loss: 11108.0918 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  36 -Loss: 11297.2617 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  37 -Loss: 10873.9219 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  38 -Loss: 11777.4824 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  39 -Loss:  9688.5430 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  40 -Loss:  7936.4844 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  41 -Loss:  9327.0312 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  42 -Loss:  9330.3301 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  43 -Loss: 10307.3945 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  44 -Loss:  9276.4941 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  45 -Loss:  7420.7104 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  46 -Loss: 10061.2236 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  47 -Loss:  8238.3311 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  48 -Loss:  9019.0938 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  49 -Loss: 10176.1426 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  50 -Loss:  8796.3604 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  51 -Loss:  8471.4141 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  52 -Loss:  8579.0801 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  53 -Loss:  6984.3013 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  54 -Loss:  7729.2148 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  55 -Loss:  7447.3105 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  56 -Loss:  9889.6543 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  57 -Loss:  7514.4897 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  58 -Loss:  7784.1865 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  59 -Loss:  6565.5967 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  60 -Loss:  6971.9473 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  61 -Loss:  6607.4316 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  62 -Loss:  8268.7051 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  63 -Loss:  6670.9937 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  64 -Loss:  7867.7139 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  65 -Loss:  6335.4971 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  66 -Loss:  6008.4048 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  67 -Loss:  6743.2842 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  68 -Loss:  7378.5381 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  69 -Loss:  5705.9507 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  70 -Loss:  5583.4385 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  71 -Loss:  6572.0068 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  72 -Loss:  6799.2954 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  73 -Loss:  6732.9390 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  74 -Loss:  4955.3901 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  75 -Loss:  6025.3809 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  76 -Loss:  5895.8140 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  77 -Loss:  5693.8408 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  78 -Loss:  4868.9004 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  79 -Loss:  6705.3501 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  80 -Loss:  6034.9131 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  81 -Loss:  4777.8442 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  82 -Loss:  4703.8350 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  83 -Loss:  7039.4580 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  84 -Loss:  5602.6094 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  85 -Loss:  4477.3110 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  86 -Loss:  4788.4111 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  87 -Loss:  5482.0303 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  88 -Loss:  5112.3750 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  89 -Loss:  4412.9004 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  90 -Loss:  4994.5801 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  91 -Loss:  5033.5381 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  92 -Loss:  4142.0996 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  93 -Loss:  5554.2480 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  94 -Loss:  6248.1318 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  95 -Loss:  4559.0918 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  96 -Loss:  4231.3149 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  97 -Loss:  4354.4136 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  98 -Loss:  5892.1709 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  99 -Loss:  5153.2607 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 100 -Loss:  4079.4197 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 101 -Loss:  3112.5029 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 102 -Loss:  5537.8921 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 103 -Loss:  4226.6299 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 104 -Loss:  4312.4507 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 105 -Loss:  3851.5364 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 106 -Loss:  4984.6309 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 107 -Loss:  4060.1550 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 108 -Loss:  4419.7788 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 109 -Loss:  4079.0264 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 110 -Loss:  3773.5571 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 111 -Loss:  3736.1670 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 112 -Loss:  4094.6648 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 113 -Loss:  4349.5610 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 114 -Loss:  3739.3660 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 115 -Loss:  4405.5908 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 116 -Loss:  4753.5654 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 117 -Loss:  3858.6091 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 118 -Loss:  3726.5200 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 119 -Loss:  3388.0317 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 120 -Loss:  4067.8230 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 121 -Loss:  3150.5945 Validation Accuracy: 0.582031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 122 -Loss:  3817.3621 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 123 -Loss:  3842.1741 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 124 -Loss:  3129.9062 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 125 -Loss:  3934.8916 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 126 -Loss:  3225.8979 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 127 -Loss:  3820.1223 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 128 -Loss:  3191.0347 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 129 -Loss:  4429.4180 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 130 -Loss:  3583.1167 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 131 -Loss:  3718.4319 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 132 -Loss:  3728.9287 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 133 -Loss:  3733.8628 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 134 -Loss:  3523.2690 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 135 -Loss:  2017.6597 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 136 -Loss:  3874.8965 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 137 -Loss:  3548.3889 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 138 -Loss:  3221.4316 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 139 -Loss:  3392.2578 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 140 -Loss:  3979.5046 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 141 -Loss:  3439.9268 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 142 -Loss:  3077.8267 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 143 -Loss:  4045.4131 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 144 -Loss:  2749.6799 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 145 -Loss:  4670.5845 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 146 -Loss:  3342.8047 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 147 -Loss:  3576.6316 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 148 -Loss:  3682.5049 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 149 -Loss:  3091.2993 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 150 -Loss:  4642.6221 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 151 -Loss:  3405.8750 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 152 -Loss:  2657.8752 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 153 -Loss:  3841.3032 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 154 -Loss:  3125.9163 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 155 -Loss:  2736.5327 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 156 -Loss:  3162.5581 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 157 -Loss:  3535.1311 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 158 -Loss:  3332.5630 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 159 -Loss:  3844.3572 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 160 -Loss:  2805.7019 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 161 -Loss:  2643.1362 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 162 -Loss:  2356.0146 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 163 -Loss:  2534.7114 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 164 -Loss:  2686.0061 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 165 -Loss:  2922.4072 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 166 -Loss:  2877.4949 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 167 -Loss:  2792.7371 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 168 -Loss:  2958.2920 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 169 -Loss:  2744.6841 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 170 -Loss:  2604.2356 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 171 -Loss:  3425.6240 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 172 -Loss:  2559.7754 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 173 -Loss:  2492.4941 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 174 -Loss:  3217.8018 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 175 -Loss:  2529.9326 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 176 -Loss:  2744.6567 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 177 -Loss:  3891.2573 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 178 -Loss:  3171.7903 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 179 -Loss:  2740.3198 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 180 -Loss:  3625.7607 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 181 -Loss:  2519.9468 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 182 -Loss:  2921.9189 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 183 -Loss:  2759.1523 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 184 -Loss:  3374.2014 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 185 -Loss:  2876.9902 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 186 -Loss:  2180.8728 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 187 -Loss:  2305.8665 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 188 -Loss:  2432.1819 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 189 -Loss:  2223.7744 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 190 -Loss:  3387.7151 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 191 -Loss:  2494.2097 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 192 -Loss:  3090.4412 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 193 -Loss:  2780.8611 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 194 -Loss:  3038.8042 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 195 -Loss:  2044.8286 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 196 -Loss:  2839.6599 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 197 -Loss:  2867.1357 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 198 -Loss:  2633.1035 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 199 -Loss:  2994.5454 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 200 -Loss:  2103.1423 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 201 -Loss:  2294.0964 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 202 -Loss:  2789.0811 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 203 -Loss:  2716.5547 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 204 -Loss:  2821.0649 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 205 -Loss:  2600.4138 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 206 -Loss:  1693.9070 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 207 -Loss:  2783.8579 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 208 -Loss:  2512.7686 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 209 -Loss:  2762.5247 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 210 -Loss:  2827.9272 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 211 -Loss:  2444.9819 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 212 -Loss:  2306.2905 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 213 -Loss:  2732.3132 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 214 -Loss:  2511.0303 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 215 -Loss:  2072.1995 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 216 -Loss:  2785.1641 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 217 -Loss:  2602.4773 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 218 -Loss:  1683.0352 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 219 -Loss:  2362.5654 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 220 -Loss:  2087.1455 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 221 -Loss:  2852.2363 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 222 -Loss:  2339.0181 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 223 -Loss:  1974.0051 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 224 -Loss:  2328.5327 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 225 -Loss:  1685.7112 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 226 -Loss:  2524.7930 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 227 -Loss:  2434.9937 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 228 -Loss:  2295.1594 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 229 -Loss:  2430.4321 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 230 -Loss:  2874.2598 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 231 -Loss:  2209.6287 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 232 -Loss:  1482.1113 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 233 -Loss:  2646.1331 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 234 -Loss:  1968.3103 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 235 -Loss:  2452.4648 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 236 -Loss:  2138.4834 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 237 -Loss:  1450.7601 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 238 -Loss:  2518.1523 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 239 -Loss:  1928.9941 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 240 -Loss:  1897.7865 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 241 -Loss:  2313.8135 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 242 -Loss:  1993.3206 Validation Accuracy: 0.699219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 243 -Loss:  2221.7991 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 244 -Loss:  1799.3040 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 245 -Loss:  2014.8044 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 246 -Loss:  2317.6743 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 247 -Loss:  2491.1558 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 248 -Loss:  1423.5707 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 249 -Loss:  2221.0195 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 250 -Loss:  2872.6406 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 251 -Loss:  1630.3405 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 252 -Loss:  1577.6605 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 253 -Loss:  1816.7122 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 254 -Loss:  1828.1387 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 255 -Loss:  1517.9529 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 256 -Loss:  2303.6494 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 257 -Loss:  2116.2275 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 258 -Loss:  1172.6823 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 259 -Loss:  1561.4143 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 260 -Loss:  1823.3484 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 261 -Loss:  2627.7732 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 262 -Loss:  2261.7988 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 263 -Loss:  1830.0555 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 264 -Loss:  1567.0344 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 265 -Loss:  2498.8574 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 266 -Loss:  2510.9431 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 267 -Loss:  2419.7839 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 268 -Loss:  2010.8342 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 269 -Loss:  2171.5574 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 270 -Loss:  1931.2534 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 271 -Loss:  2175.7634 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 272 -Loss:  1813.9202 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 273 -Loss:  1697.4509 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 274 -Loss:  3015.6592 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 275 -Loss:  1874.5798 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 276 -Loss:  2550.9678 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 277 -Loss:  2117.7437 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 278 -Loss:  1552.8984 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 279 -Loss:  2027.6995 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 280 -Loss:  2262.3315 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 281 -Loss:  1641.1055 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 282 -Loss:  1423.7009 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 283 -Loss:  1576.2014 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 284 -Loss:  1480.4285 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 285 -Loss:  1491.8108 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 286 -Loss:  1907.6746 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 287 -Loss:  1953.7117 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 288 -Loss:  1481.2649 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 289 -Loss:  2171.3545 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 290 -Loss:  1332.2112 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 291 -Loss:  1457.6724 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 292 -Loss:  2345.2842 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 293 -Loss:  2039.8303 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 294 -Loss:  1576.0510 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 295 -Loss:  2072.0566 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 296 -Loss:  2168.1284 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 297 -Loss:  1649.2366 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 298 -Loss:  1807.7910 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 299 -Loss:  1656.8806 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 300 -Loss:  1538.3645 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 301 -Loss:  1269.9464 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 302 -Loss:  1725.2164 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 303 -Loss:  2560.3950 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 304 -Loss:  1739.1111 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 305 -Loss:  1887.5487 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 306 -Loss:  1672.1102 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 307 -Loss:  2100.5925 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 308 -Loss:  1515.3000 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 309 -Loss:  2306.6897 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 310 -Loss:  1274.5923 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 311 -Loss:  1671.1357 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 312 -Loss:  1957.8584 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 313 -Loss:  2369.6406 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 314 -Loss:  2499.7285 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 315 -Loss:  1793.9191 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 316 -Loss:  2368.6514 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 317 -Loss:  1720.3621 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 318 -Loss:  1367.9719 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 319 -Loss:  1593.8966 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 320 -Loss:  2278.0923 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 321 -Loss:  1474.6631 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 322 -Loss:  1684.5139 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 323 -Loss:  1745.1058 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 324 -Loss:  2062.4067 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 325 -Loss:  1546.7124 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 326 -Loss:  1751.2366 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 327 -Loss:  2278.3728 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 328 -Loss:  1498.4993 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 329 -Loss:  1347.7837 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 330 -Loss:  1971.1653 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 331 -Loss:  1955.1907 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 332 -Loss:  1788.5916 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 333 -Loss:  1899.3105 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 334 -Loss:  1460.0171 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 335 -Loss:  1493.1921 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 336 -Loss:  1504.5603 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 337 -Loss:  2664.6816 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 338 -Loss:  1624.1769 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 339 -Loss:  1505.8518 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 340 -Loss:  1969.6389 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 341 -Loss:  1325.0215 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 342 -Loss:  1373.7581 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 343 -Loss:  1272.3523 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 344 -Loss:  1441.7501 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 345 -Loss:  1430.4382 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 346 -Loss:  2563.8281 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 347 -Loss:  2267.5889 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 348 -Loss:  1308.6362 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 349 -Loss:  1658.1748 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 350 -Loss:  1341.0422 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 351 -Loss:  1658.4152 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 352 -Loss:  1161.7800 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 353 -Loss:  1210.8625 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 354 -Loss:  1875.0934 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 355 -Loss:  1015.2929 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 356 -Loss:  1752.4657 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 357 -Loss:  1700.8838 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 358 -Loss:  1474.6948 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 359 -Loss:  1247.9707 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 360 -Loss:  1812.9111 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 361 -Loss:  1940.4354 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 362 -Loss:  1349.2805 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 363 -Loss:  1723.3472 Validation Accuracy: 0.718750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 364 -Loss:  1581.2534 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 365 -Loss:  1141.9279 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 366 -Loss:  1545.2380 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 367 -Loss:  1407.3937 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 368 -Loss:  1342.1101 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 369 -Loss:  2056.7539 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 370 -Loss:  1377.2935 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 371 -Loss:  1336.0989 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 372 -Loss:  1086.4241 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 373 -Loss:  1416.7201 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 374 -Loss:  1602.9491 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 375 -Loss:  1184.2458 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 376 -Loss:  1399.7308 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 377 -Loss:  1136.5446 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 378 -Loss:   812.1174 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 379 -Loss:  1460.1947 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 380 -Loss:  1206.6624 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 381 -Loss:  1897.5123 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 382 -Loss:  1050.3486 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 383 -Loss:  1534.3729 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 384 -Loss:  1796.4058 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 385 -Loss:  1495.6311 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 386 -Loss:  1151.4937 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 387 -Loss:  1607.0996 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 388 -Loss:  1267.9908 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 389 -Loss:  1475.4852 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 390 -Loss:  1304.8657 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 391 -Loss:  1058.0613 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 392 -Loss:  1105.3118 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 393 -Loss:  1420.9855 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 394 -Loss:  1389.1133 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 395 -Loss:  1070.2626 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 396 -Loss:  1511.5059 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 397 -Loss:   888.7017 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 398 -Loss:  1111.7356 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 399 -Loss:  1135.1501 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 400 -Loss:  1150.3149 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 401 -Loss:  1215.6389 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 402 -Loss:  1147.1033 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 403 -Loss:  1681.6062 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 404 -Loss:  1486.4753 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 405 -Loss:  1003.1507 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 406 -Loss:  1617.7670 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 407 -Loss:  1688.2920 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 408 -Loss:  1545.7810 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 409 -Loss:  1007.5869 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 410 -Loss:  1744.5929 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 411 -Loss:   802.1747 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 412 -Loss:  1455.1483 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 413 -Loss:  1205.9500 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 414 -Loss:  1502.2371 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 415 -Loss:   860.1711 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 416 -Loss:  1276.8960 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 417 -Loss:   989.0409 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 418 -Loss:  1937.9070 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 419 -Loss:  1164.9847 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 420 -Loss:  1162.0154 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 421 -Loss:  1205.8484 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 422 -Loss:  1224.7592 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 423 -Loss:  1377.4622 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 424 -Loss:  1501.1030 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 425 -Loss:  1290.5632 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 426 -Loss:  1255.8044 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 427 -Loss:  1470.1835 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 428 -Loss:  1450.3772 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 429 -Loss:  1201.9810 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch   1 -Loss:  1474.5798 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch   2 -Loss:  1488.9198 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch   3 -Loss:  1301.8375 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch   4 -Loss:  1516.6971 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch   5 -Loss:  1529.1401 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch   6 -Loss:  1163.7211 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch   7 -Loss:  1446.8179 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch   8 -Loss:  1303.9385 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch   9 -Loss:  1615.4587 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  10 -Loss:  1514.0526 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  11 -Loss:   933.9188 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  12 -Loss:  1832.8925 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  13 -Loss:  1438.4332 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  14 -Loss:  1182.2393 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  15 -Loss:  1438.0070 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  16 -Loss:  1099.4877 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  17 -Loss:  1040.0559 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  18 -Loss:  1012.7831 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  19 -Loss:  1066.7661 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  20 -Loss:  1264.4739 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  21 -Loss:  1118.3887 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  22 -Loss:  1669.1871 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  23 -Loss:  1709.3781 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  24 -Loss:  1000.7008 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  25 -Loss:  1359.9304 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  26 -Loss:   961.3195 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  27 -Loss:  1620.2681 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  28 -Loss:  1184.1240 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  29 -Loss:  1239.7369 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  30 -Loss:  1085.1788 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  31 -Loss:  1301.8582 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  32 -Loss:  1411.9688 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  33 -Loss:  1438.2894 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  34 -Loss:  1009.3259 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  35 -Loss:  1025.7961 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  36 -Loss:  1018.3699 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  37 -Loss:  1489.4304 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  38 -Loss:  1330.7487 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  39 -Loss:  1124.9583 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  40 -Loss:  1211.3994 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  41 -Loss:  1438.1726 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  42 -Loss:  1375.4236 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  43 -Loss:   967.9697 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  44 -Loss:  1077.4800 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  45 -Loss:   802.1061 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  46 -Loss:  1206.5156 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  47 -Loss:  1076.9342 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  48 -Loss:  1200.4678 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  49 -Loss:  1123.1481 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  50 -Loss:  1197.8403 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  51 -Loss:  1057.0916 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  52 -Loss:  1221.7645 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  53 -Loss:  1066.6243 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  54 -Loss:  1078.7175 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  55 -Loss:  1121.5256 Validation Accuracy: 0.761719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch  56 -Loss:  1295.5151 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  57 -Loss:   970.6605 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  58 -Loss:   973.0881 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  59 -Loss:  1113.1133 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  60 -Loss:  2004.5427 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  61 -Loss:  1119.8352 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  62 -Loss:  1281.9438 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  63 -Loss:  1048.2214 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  64 -Loss:  1074.9502 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  65 -Loss:  1081.4515 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  66 -Loss:  1376.4039 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  67 -Loss:  1529.2141 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  68 -Loss:   811.2931 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  69 -Loss:  1524.4436 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  70 -Loss:  1109.3508 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  71 -Loss:  1271.9526 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  72 -Loss:  1336.6030 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  73 -Loss:   699.7773 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  74 -Loss:  1084.3049 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  75 -Loss:  1287.3657 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  76 -Loss:  1057.6130 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  77 -Loss:  1165.3027 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  78 -Loss:   928.7380 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  79 -Loss:   992.4948 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  80 -Loss:   751.2446 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  81 -Loss:  1044.3046 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  82 -Loss:  1298.3066 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  83 -Loss:  1147.6464 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  84 -Loss:   717.6644 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  85 -Loss:  1092.1526 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  86 -Loss:  1185.1597 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  87 -Loss:   919.2147 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  88 -Loss:  1078.1564 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  89 -Loss:  1339.6436 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  90 -Loss:  1132.9270 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  91 -Loss:   972.3807 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  92 -Loss:  1068.7126 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  93 -Loss:   807.5737 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  94 -Loss:   892.4171 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  95 -Loss:  1154.7783 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  96 -Loss:  1097.3401 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  97 -Loss:  1345.9718 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  98 -Loss:  1129.3156 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  99 -Loss:  1305.3489 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 100 -Loss:   933.8269 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 101 -Loss:   897.6668 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 102 -Loss:   795.1848 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 103 -Loss:   951.2965 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 104 -Loss:   587.3344 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 105 -Loss:  1068.5974 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 106 -Loss:   829.4591 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 107 -Loss:   856.6991 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 108 -Loss:  1545.2716 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 109 -Loss:  1046.7307 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 110 -Loss:  1041.4309 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 111 -Loss:   964.7643 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 112 -Loss:  1199.9839 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 113 -Loss:  1173.3851 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 114 -Loss:  1180.1392 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 115 -Loss:  1059.0786 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 116 -Loss:   870.2568 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 117 -Loss:  1268.5601 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 118 -Loss:  1044.4865 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 119 -Loss:   800.8781 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 120 -Loss:   713.7620 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 121 -Loss:   948.7067 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 122 -Loss:  1192.6808 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 123 -Loss:  1403.4475 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 124 -Loss:  1333.4316 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 125 -Loss:  1083.6896 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 126 -Loss:  1171.0457 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 127 -Loss:   844.5461 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 128 -Loss:  1284.7764 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 129 -Loss:   964.0332 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 130 -Loss:  1045.0092 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 131 -Loss:  1060.2170 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 132 -Loss:  1687.8936 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 133 -Loss:  1053.7764 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 134 -Loss:   962.1152 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 135 -Loss:   654.1502 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 136 -Loss:   835.2533 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 137 -Loss:  1038.7903 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 138 -Loss:   752.6765 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 139 -Loss:   776.1775 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 140 -Loss:   762.4394 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 141 -Loss:  1441.7998 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 142 -Loss:  1220.6654 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 143 -Loss:   949.6982 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 144 -Loss:   736.4023 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 145 -Loss:  1262.9106 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 146 -Loss:  1075.0369 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 147 -Loss:   775.4834 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 148 -Loss:  1070.9453 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 149 -Loss:   848.2527 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 150 -Loss:  1190.3741 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 151 -Loss:  1063.4675 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 152 -Loss:  1093.5852 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 153 -Loss:  1120.1492 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 154 -Loss:  1298.4834 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 155 -Loss:  1290.1427 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 156 -Loss:  1128.4351 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 157 -Loss:   927.9779 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 158 -Loss:  1061.8838 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 159 -Loss:   948.6200 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 160 -Loss:   810.0934 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 161 -Loss:   952.4655 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 162 -Loss:  1082.6542 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 163 -Loss:   753.9462 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 164 -Loss:   794.9461 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 165 -Loss:  1060.7668 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 166 -Loss:  1039.5925 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 167 -Loss:  1629.9746 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 168 -Loss:  1081.6460 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 169 -Loss:   750.2053 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 170 -Loss:  1211.2531 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 171 -Loss:  1527.0640 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 172 -Loss:  1167.4939 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 173 -Loss:  1070.4189 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 174 -Loss:   782.3350 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 175 -Loss:   931.8805 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 176 -Loss:  1025.3916 Validation Accuracy: 0.785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 177 -Loss:   869.6436 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 178 -Loss:   889.9225 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 179 -Loss:   760.2213 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 180 -Loss:  1148.8629 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 181 -Loss:   799.0298 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 182 -Loss:  1052.5358 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 183 -Loss:  1186.4578 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 184 -Loss:  1016.9252 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 185 -Loss:  1008.6650 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 186 -Loss:   599.9887 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 187 -Loss:   848.6582 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 188 -Loss:  1058.3086 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 189 -Loss:   853.4786 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 190 -Loss:   776.8099 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 191 -Loss:   884.2421 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 192 -Loss:  1561.0332 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 193 -Loss:   734.5956 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 194 -Loss:  1202.2190 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 195 -Loss:   924.0393 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 196 -Loss:  1031.2722 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 197 -Loss:  1238.4424 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 198 -Loss:   826.0659 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 199 -Loss:  1420.5581 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 200 -Loss:   935.0087 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 201 -Loss:   864.7652 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 202 -Loss:   775.7976 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 203 -Loss:   914.2457 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 204 -Loss:  1094.1346 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 205 -Loss:   782.6710 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 206 -Loss:   917.1947 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 207 -Loss:   834.9292 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 208 -Loss:   925.5121 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 209 -Loss:  1027.1289 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 210 -Loss:  1127.0557 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 211 -Loss:  1388.7515 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 212 -Loss:  1059.2200 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 213 -Loss:   613.7411 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 214 -Loss:   906.0847 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 215 -Loss:  1039.0098 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 216 -Loss:   923.3167 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 217 -Loss:  1036.6151 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 218 -Loss:   732.1157 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 219 -Loss:  1095.9175 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 220 -Loss:   718.2279 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 221 -Loss:  1139.4341 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 222 -Loss:   761.4718 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 223 -Loss:   841.3507 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 224 -Loss:   722.8114 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 225 -Loss:   830.3280 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 226 -Loss:   767.1865 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 227 -Loss:   693.8031 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 228 -Loss:   996.5493 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 229 -Loss:  1008.1367 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 230 -Loss:  1172.3369 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 231 -Loss:   995.8785 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 232 -Loss:  1124.4963 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 233 -Loss:   727.5723 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 234 -Loss:   938.2656 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 235 -Loss:   637.1089 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 236 -Loss:  1156.2683 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 237 -Loss:   859.2375 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 238 -Loss:  1158.0779 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 239 -Loss:  1042.7717 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 240 -Loss:  1043.7578 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 241 -Loss:  1208.6152 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 242 -Loss:  1151.0563 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 243 -Loss:   850.1061 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 244 -Loss:  1295.0729 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 245 -Loss:   686.4432 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 246 -Loss:   906.3719 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 247 -Loss:  1244.4910 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 248 -Loss:   874.7070 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 249 -Loss:   703.3167 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 250 -Loss:   872.9264 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 251 -Loss:   931.0344 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 252 -Loss:   859.7057 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 253 -Loss:  1141.8148 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 254 -Loss:  1066.0151 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 255 -Loss:  1030.5182 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 256 -Loss:   687.8757 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 257 -Loss:   666.1319 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 258 -Loss:   780.5619 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 259 -Loss:   777.4554 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 260 -Loss:  1054.2297 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 261 -Loss:  1235.2983 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 262 -Loss:  1236.7632 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 263 -Loss:   739.0121 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 264 -Loss:   957.4757 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 265 -Loss:   974.8525 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 266 -Loss:   873.4614 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 267 -Loss:  1045.6898 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 268 -Loss:   666.5043 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 269 -Loss:   845.6022 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 270 -Loss:   786.1452 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 271 -Loss:   933.0747 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 272 -Loss:   758.3640 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 273 -Loss:   826.7689 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 274 -Loss:   363.2027 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 275 -Loss:   883.6656 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 276 -Loss:  1100.7050 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 277 -Loss:  1010.5314 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 278 -Loss:  1069.5925 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 279 -Loss:  1005.6768 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 280 -Loss:   836.7913 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 281 -Loss:   892.5768 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 282 -Loss:   859.9618 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 283 -Loss:   660.5443 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 284 -Loss:   762.6729 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 285 -Loss:  1144.4033 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 286 -Loss:   804.2024 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 287 -Loss:   546.6559 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 288 -Loss:   734.9819 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 289 -Loss:   957.9778 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 290 -Loss:   655.6638 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 291 -Loss:   745.6262 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 292 -Loss:   971.4878 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 293 -Loss:   744.6332 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 294 -Loss:   818.0802 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 295 -Loss:   855.9796 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 296 -Loss:  1127.1996 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 297 -Loss:   546.7651 Validation Accuracy: 0.781250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 298 -Loss:   906.2830 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 299 -Loss:   996.0255 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 300 -Loss:   850.3007 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 301 -Loss:   927.8784 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 302 -Loss:   923.4951 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 303 -Loss:   730.9117 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 304 -Loss:   655.9620 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 305 -Loss:   803.0916 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 306 -Loss:   709.6015 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 307 -Loss:   718.1379 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 308 -Loss:   628.3855 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 309 -Loss:   709.2906 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 310 -Loss:   703.7634 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 311 -Loss:  1099.0283 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 312 -Loss:   561.6818 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 313 -Loss:   482.9353 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 314 -Loss:   646.6791 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 315 -Loss:   700.5413 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 316 -Loss:   881.9094 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 317 -Loss:   778.5217 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 318 -Loss:   912.4358 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 319 -Loss:   774.9519 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 320 -Loss:   961.8710 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 321 -Loss:   896.1870 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 322 -Loss:   665.6668 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 323 -Loss:  1248.6627 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 324 -Loss:   962.8068 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 325 -Loss:   774.8632 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 326 -Loss:   634.6447 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 327 -Loss:   788.7224 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 328 -Loss:   916.5478 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 329 -Loss:   794.2784 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 330 -Loss:  1197.3738 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 331 -Loss:   707.5426 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 332 -Loss:   926.8919 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 333 -Loss:   845.3232 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 334 -Loss:   688.0530 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 335 -Loss:   947.3631 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 336 -Loss:  1015.3617 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 337 -Loss:   638.6461 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 338 -Loss:   872.8497 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 339 -Loss:   685.0029 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 340 -Loss:   907.1251 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 341 -Loss:   613.1010 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 342 -Loss:   621.4025 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 343 -Loss:   831.8977 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 344 -Loss:   632.3009 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 345 -Loss:   785.2020 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 346 -Loss:   583.8153 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 347 -Loss:   643.3852 Validation Accuracy: 0.773438\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf. global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} -'\n",
    "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
